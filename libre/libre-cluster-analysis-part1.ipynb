{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project&data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims at providing T1 diabetes management support through machine learning data analytics performed on wearable sensor data signals. The dataset was acquired on a study that included 20 patients with T1 diabetes using freestyle LibreLink from the diabetes center of Royal Berkshire Hospital.\n",
    "\n",
    "This is the first stage of this project , we focus on the clustering of glucose time series data and find out the phenotype based on glucose variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import _pickle as pickle\n",
    "import datetime\n",
    "import numbers\n",
    "import numpy as np\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "import itertools\n",
    "from random import sample "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Formalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original dataset are noisy, the first step of preprocessing is to merge duplicated data and transform time index using Pandas ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bg(df1, countNo):\n",
    "    df1['bg'] = df1['Historic Glucose mmol/L'].fillna(df1['Scan Glucose mmol/L'])\n",
    "    df_p = df1[['Device Timestamp','bg']]\n",
    "    df_p.columns = ['time', 'bg']\n",
    "    df_p['time'] = pd.to_datetime(df_p['time'], format='%d-%m-%Y %H:%M')\n",
    "    df_p = df_p.set_index('time').sort_index(ascending=True)\n",
    "#     df_p = df_p.interpolate()\n",
    "    df_p['No'] = countNo\n",
    "    return df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "countNo = 0\n",
    "for file in os.listdir('../data/libre/'):\n",
    "#     print(file)\n",
    "    if file.find('.csv')!=-1:\n",
    "        df = pd.read_csv('../data/libre/'+file)\n",
    "        df_p = extract_bg(df, countNo)\n",
    "        dfs.append(df_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step, we partitioned the long time series data into different sizes of windows, we defined overlap ratio of each dataset to represent how much the adajcent windows are overlapped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_concecutive(df, minutes_step=150, each_gap=15, over_lap=0):\n",
    "    # df the data to be processed \n",
    "    # minutes_step  window size\n",
    "    # each_gap  split\n",
    "    counts = int(minutes_step/each_gap)\n",
    "    lag = math.ceil(counts *(1 - over_lap))\n",
    "    print('No=', df.No[0])\n",
    "    sep_sets = []\n",
    "    len_index = len(df.index)\n",
    "    for i in range(0, len_index, lag):\n",
    "        sep = []\n",
    "        prev_i = df.index[i]\n",
    "        prev_bg = df.loc[prev_i].bg\n",
    "        if isinstance(prev_bg, float):\n",
    "            sep.append(prev_bg)\n",
    "        else:\n",
    "            pass\n",
    "        for j in range(counts):\n",
    "            next_i = prev_i + datetime.timedelta(minutes=each_gap)\n",
    "            if df.index.contains(next_i):\n",
    "                next_bg = df.loc[next_i].bg\n",
    "                if isinstance(next_bg, float):\n",
    "                    sep.append(next_bg)\n",
    "                prev_i = next_i\n",
    "            else:\n",
    "                sep = []\n",
    "                break                \n",
    "        if len(sep) == (counts+1):\n",
    "            sep_sets.append(sep)\n",
    "    return sep_sets \n",
    "\n",
    "# 2D --> 1D\n",
    "def flattern(all_sets):\n",
    "    all_sets_flat = list(itertools.chain.from_iterable(all_sets))\n",
    "    df_all = pd.DataFrame(np.stack(all_sets_flat))\n",
    "    df_all.fillna(method ='pad',inplace=True)\n",
    "    return df_all\n",
    "dfs_sub = dfs[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The range of window sizes is 120min, 150min and 180min. The range of over_lap ratios is 0, 0.25, 0.5 and 0.75. Thus we have 3*4=12 combinations. To boost the speed of calculation, we employed parallel computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets =[]\n",
    "for step in (60,90,120,150,180):\n",
    "    for ratio in (0, 0.25, 0.5, 0.75):\n",
    "        print('step:',step)\n",
    "        print('overlap_ratio:', ratio)\n",
    "        _set = Parallel(n_jobs=-1)(delayed(select_concecutive)(df,minutes_step=step, over_lap=ratio) for df in tqdm(dfs_sub))\n",
    "        df_set = flattern(_set)\n",
    "        df_set.to_csv('datasets2/'+str(step)+'_'+str(ratio)+'.csv', index=False)\n",
    "        data_sets.append(df_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering evaluation(Part 2 with R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
