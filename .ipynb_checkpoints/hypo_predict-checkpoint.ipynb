{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "pd.options.display.precision = 15\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import datetime\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import _pickle as pickle\n",
    "\n",
    "\n",
    "from scipy.signal import hilbert\n",
    "from scipy.signal import hann\n",
    "from scipy.signal import convolve\n",
    "from scipy import stats\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_path = '/home/jupyter/work/openaps/data/99908129/direct-sharing-31/entries_2017-01-01_to_2017-10-24.json'\n",
    "df_bg = pd.read_json(bg_path)\n",
    "df_bg = df_bg[['date', 'sgv', 'type']]\n",
    "df_bg = df_bg.set_index('date').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff8a4410e80>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### prepare traing \n",
    "sample = df_bg['2017-04-01':'2017-05-01']\n",
    "sample[sample.sgv<=72].plot(y='sgv', style = '.', figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Compute time to hypo\n",
    "# this can be improved\n",
    "df_bg['hypo_t']= 0\n",
    "n = len(df_bg)\n",
    "for i in range(n):\n",
    "    j=i\n",
    "    while j<n-1 and df_bg.iloc[j].sgv>72:\n",
    "        j+=1\n",
    "    time_to_hypo = (math.floor((df_bg.index[j]-df_bg.index[i]).total_seconds()/60))\n",
    "    df_bg.loc[df_bg.index[i], 'hypo_t'] = time_to_hypo\n",
    "#     row['hypo_t'] = df_bg.iloc[j].date - row.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df_bg, open('data/df_bg_99908129.pkl', 'wb'), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bg = pickle.load(open('data/df_bg_99908129.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c11dec797145259b254eff3009a349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2311), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "train = df_bg\n",
    "rows = 24\n",
    "segments = int(np.floor(train.shape[0] / rows))\n",
    "def add_trend_feature(arr, abs_values=False):\n",
    "    idx = np.array(range(len(arr)))\n",
    "    if abs_values:\n",
    "        arr = np.abs(arr)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(idx.reshape(-1, 1), arr)\n",
    "    return lr.coef_[0]\n",
    "\n",
    "def classic_sta_lta(x, length_sta, length_lta):\n",
    "    \n",
    "    sta = np.cumsum(x ** 2)\n",
    "\n",
    "    # Convert to float\n",
    "    sta = np.require(sta, dtype=np.float)\n",
    "\n",
    "    # Copy for LTA\n",
    "    lta = sta.copy()\n",
    "\n",
    "    # Compute the STA and the LTA\n",
    "    sta[length_sta:] = sta[length_sta:] - sta[:-length_sta]\n",
    "    sta /= length_sta\n",
    "    lta[length_lta:] = lta[length_lta:] - lta[:-length_lta]\n",
    "    lta /= length_lta\n",
    "\n",
    "    # Pad zeros\n",
    "    sta[:length_lta - 1] = 0\n",
    "\n",
    "    # Avoid division by zero by setting zero values to tiny float\n",
    "    dtiny = np.finfo(0.0).tiny\n",
    "    idx = lta < dtiny\n",
    "    lta[idx] = dtiny\n",
    "\n",
    "    return sta / lta\n",
    "\n",
    "X_tr = pd.DataFrame(index=range(segments), dtype=np.float64)\n",
    "\n",
    "y_tr = pd.DataFrame(index=range(segments), dtype=np.float64, columns=['hypo_t'])\n",
    "\n",
    "\n",
    "total_mean = train['sgv'].mean()\n",
    "total_std = train['sgv'].std()\n",
    "total_max = train['sgv'].max()\n",
    "total_min = train['sgv'].min()\n",
    "total_sum = train['sgv'].sum()\n",
    "total_abs_sum = np.abs(train['sgv']).sum()\n",
    "\n",
    "def calc_change_rate(x):\n",
    "    change = (np.diff(x) / x[:-1]).values\n",
    "    change = change[np.nonzero(change)[0]]\n",
    "    change = change[~np.isnan(change)]\n",
    "    change = change[change != -np.inf]\n",
    "    change = change[change != np.inf]\n",
    "    return np.mean(change)\n",
    "\n",
    "for segment in tqdm_notebook(range(segments)):\n",
    "    seg = train.iloc[segment*rows:segment*rows+rows]\n",
    "    x = pd.Series(seg['sgv'].values)\n",
    "    y = seg['hypo_t'].values[-1]\n",
    "    \n",
    "    y_tr.loc[segment, 'hypo_t'] = y\n",
    "    X_tr.loc[segment, 'mean'] = x.mean()\n",
    "    X_tr.loc[segment, 'std'] = x.std()\n",
    "    X_tr.loc[segment, 'max'] = x.max()\n",
    "    X_tr.loc[segment, 'min'] = x.min()\n",
    "    \n",
    "    X_tr.loc[segment, 'mean_change_abs'] = np.mean(np.diff(x))\n",
    "    X_tr.loc[segment, 'mean_change_rate'] = calc_change_rate(x)\n",
    "    X_tr.loc[segment, 'abs_max'] = np.abs(x).max()\n",
    "    X_tr.loc[segment, 'abs_min'] = np.abs(x).min()\n",
    "    \n",
    "   \n",
    "    X_tr.loc[segment, 'max_to_min'] = x.max() / np.abs(x.min())\n",
    "    X_tr.loc[segment, 'max_to_min_diff'] = x.max() - np.abs(x.min())\n",
    "    X_tr.loc[segment, 'count_low'] = len(x[np.abs(x) < 100])\n",
    "    X_tr.loc[segment, 'sum'] = x.sum()\n",
    "\n",
    "    X_tr.loc[segment, 'trend'] = add_trend_feature(x)\n",
    "    X_tr.loc[segment, 'abs_trend'] = add_trend_feature(x, abs_values=True)\n",
    "    X_tr.loc[segment, 'abs_mean'] = np.abs(x).mean()\n",
    "    X_tr.loc[segment, 'abs_std'] = np.abs(x).std()\n",
    "    \n",
    "    X_tr.loc[segment, 'mad'] = x.mad()\n",
    "    X_tr.loc[segment, 'kurt'] = x.kurtosis()\n",
    "    X_tr.loc[segment, 'skew'] = x.skew()\n",
    "    X_tr.loc[segment, 'med'] = x.median()\n",
    "    \n",
    "    \n",
    "#     for windows in [2, 4, 6]:\n",
    "#         x_roll_std = x.rolling(windows).std().dropna().values\n",
    "#         x_roll_mean = x.rolling(windows).mean().dropna().values\n",
    "        \n",
    "#         X_tr.loc[segment, 'ave_roll_std_' + str(windows)] = x_roll_std.mean()\n",
    "#         X_tr.loc[segment, 'std_roll_std_' + str(windows)] = x_roll_std.std()\n",
    "#         X_tr.loc[segment, 'max_roll_std_' + str(windows)] = x_roll_std.max()\n",
    "#         X_tr.loc[segment, 'min_roll_std_' + str(windows)] = x_roll_std.min()\n",
    "\n",
    "#         X_tr.loc[segment, 'av_change_abs_roll_std_' + str(windows)] = np.mean(np.diff(x_roll_std))\n",
    "#         X_tr.loc[segment, 'av_change_rate_roll_std_' + str(windows)] = np.mean(np.nonzero((np.diff(x_roll_std) / x_roll_std[:-1]))[0])\n",
    "#         X_tr.loc[segment, 'abs_max_roll_std_' + str(windows)] = np.abs(x_roll_std).max()\n",
    "        \n",
    "#         X_tr.loc[segment, 'ave_roll_mean_' + str(windows)] = x_roll_mean.mean()\n",
    "#         X_tr.loc[segment, 'std_roll_mean_' + str(windows)] = x_roll_mean.std()\n",
    "#         X_tr.loc[segment, 'max_roll_mean_' + str(windows)] = x_roll_mean.max()\n",
    "#         X_tr.loc[segment, 'min_roll_mean_' + str(windows)] = x_roll_mean.min()\n",
    "\n",
    "#         X_tr.loc[segment, 'av_change_abs_roll_mean_' + str(windows)] = np.mean(np.diff(x_roll_mean))\n",
    "#         X_tr.loc[segment, 'av_change_rate_roll_mean_' + str(windows)] = np.mean(np.nonzero((np.diff(x_roll_mean) / x_roll_mean[:-1]))[0])\n",
    "#         X_tr.loc[segment, 'abs_max_roll_mean_' + str(windows)] = np.abs(x_roll_mean).max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2311, 20)\n"
     ]
    }
   ],
   "source": [
    "print(X_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sum          0.241211\n",
       "mean         0.241211\n",
       "abs_mean     0.241211\n",
       "max          0.239508\n",
       "abs_max      0.239508\n",
       "min          0.232425\n",
       "abs_min      0.232425\n",
       "med          0.229335\n",
       "count_low    0.163942\n",
       "trend        0.082532\n",
       "abs_trend    0.082532\n",
       "mad          0.081939\n",
       "dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(X_tr.corrwith(y_tr['hypo_t'])).sort_values(ascending=False).head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(X_tr), columns=X_tr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(X_train_scaled, open('data/X_train_scaled_99908129.pkl', 'wb'), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pickle.load(open('data/X_train_scaled_99908129.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled, y_tr, y_test = train_test_split(X_train_scaled, y_tr, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr['hypo_t']/=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "572      0.000000000000000\n",
       "1289     7.440000000000000\n",
       "1997    33.240000000000002\n",
       "2095     1.350000000000000\n",
       "1742     0.100000000000000\n",
       "Name: hypo_t, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr['hypo_t'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X=X_train_scaled, X_test=X_test_scaled, y=y_tr, params=None, folds=folds, model_type='lgb', plot_feature_importance=False, model=None):\n",
    "\n",
    "    oof = np.zeros(len(X))\n",
    "    prediction = np.zeros(len(X_test))\n",
    "    scores = []\n",
    "    accuracies = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n",
    "        print('Fold', fold_n, 'started at', time.ctime())\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "        \n",
    "        if model_type == 'lgb':\n",
    "            model = lgb.LGBMRegressor(**params, n_estimators = 50000, n_jobs = -1)\n",
    "            model.fit(X_train, y_train, \n",
    "                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='mae',\n",
    "                    verbose=10000, early_stopping_rounds=200)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "            \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=500, params=params)\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "        \n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
    "            score = mean_absolute_error(y_valid, y_pred_valid)\n",
    "            print('f{fold:fold_n} {score:score}')\n",
    "            print('')\n",
    "            \n",
    "            y_pred = model.predict(X_test).reshape(-1,)\n",
    "        \n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostRegressor(iterations=20000,  eval_metric='MAE', **params)\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        oof[valid_index] = y_pred_valid.reshape(-1,)\n",
    "        scores.append(mean_absolute_error(y_valid, y_pred_valid))\n",
    "\n",
    "        prediction += y_pred    \n",
    "        \n",
    "        if model_type == 'lgb':\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = X.columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= n_fold\n",
    "    \n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        feature_importance[\"importance\"] /= n_fold\n",
    "        if plot_feature_importance:\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "        \n",
    "            return oof, prediction, feature_importance\n",
    "        return oof, prediction\n",
    "    \n",
    "    else:\n",
    "        return oof, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Fri Jun  7 16:33:30 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6375]\ttraining's l1: 10.2304\tvalid_1's l1: 11.0914\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "continuous is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-ec3521b79259>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m           \u001b[0;34m'reg_lambda'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.3603427518866501\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m          }\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0moof_lgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_lgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_importance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lgb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_feature_importance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-e64e3c4a660f>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(X, X_test, y, params, folds, model_type, plot_feature_importance, model)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0moof\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: continuous is not supported"
     ]
    }
   ],
   "source": [
    "params = {'num_leaves': 128,\n",
    "          'min_data_in_leaf': 79,\n",
    "          'objective': 'huber',\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.01,\n",
    "          \"boosting\": \"gbdt\",\n",
    "          \"bagging_freq\": 5,\n",
    "          \"bagging_fraction\": 0.8126672064208567,\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'mae',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 0.1302650970728192,\n",
    "          'reg_lambda': 0.3603427518866501\n",
    "         }\n",
    "oof_lgb, prediction_lgb, feature_importance = train_model(params=params, model_type='lgb', plot_feature_importance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Fri Jun  7 16:18:52 2019\n",
      "[0]\ttrain-mae:1491.04\tvalid_data-mae:1432.87\n",
      "Multiple eval metrics have been passed: 'valid_data-mae' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-mae hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[25]\ttrain-mae:945.558\tvalid_data-mae:1143.65\n",
      "\n",
      "Fold 1 started at Fri Jun  7 16:18:53 2019\n",
      "[0]\ttrain-mae:1468.11\tvalid_data-mae:1522.79\n",
      "Multiple eval metrics have been passed: 'valid_data-mae' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-mae hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[29]\ttrain-mae:887.229\tvalid_data-mae:1161.55\n",
      "\n",
      "Fold 2 started at Fri Jun  7 16:18:54 2019\n",
      "[0]\ttrain-mae:1459.48\tvalid_data-mae:1564.62\n",
      "Multiple eval metrics have been passed: 'valid_data-mae' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-mae hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[31]\ttrain-mae:821.033\tvalid_data-mae:1245.33\n",
      "\n",
      "Fold 3 started at Fri Jun  7 16:18:55 2019\n",
      "[0]\ttrain-mae:1499.04\tvalid_data-mae:1398.1\n",
      "Multiple eval metrics have been passed: 'valid_data-mae' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-mae hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[23]\ttrain-mae:968.389\tvalid_data-mae:1103.67\n",
      "\n",
      "Fold 4 started at Fri Jun  7 16:18:56 2019\n",
      "[0]\ttrain-mae:1477.19\tvalid_data-mae:1478.36\n",
      "Multiple eval metrics have been passed: 'valid_data-mae' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-mae hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[27]\ttrain-mae:914.124\tvalid_data-mae:1127.71\n",
      "\n",
      "CV mean score: 1156.3822, std: 48.3746.\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {'eta': 0.03,\n",
    "              'max_depth': 9,\n",
    "              'subsample': 0.85,\n",
    "              'objective': 'reg:linear',\n",
    "              'eval_metric': 'mae',\n",
    "              'silent': True,\n",
    "              'nthread': 4}\n",
    "oof_xgb, prediction_xgb = train_model(X=X_train_scaled, X_test=X_test_scaled, params=xgb_params, model_type='xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NuSVR(gamma='scale', nu=0.9, C=10.0, tol=0.01)\n",
    "oof_svr, prediction_svr = train_model(X=X_train_scaled, X_test=X_test_scaled, params=None, model_type='sklearn', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Fri Jun  7 16:22:00 2019\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8303a30c6344>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'MAE'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moof_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-45942ed8fa3b>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(X, X_test, y, params, folds, model_type, plot_feature_importance, model)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cat'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'MAE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_best_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0my_pred_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   3234\u001b[0m                          \u001b[0muse_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3235\u001b[0m                          \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m                          save_snapshot, snapshot_file, snapshot_interval, init_model)\n\u001b[0m\u001b[1;32m   3237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mlog_fixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_train_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1279\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_sets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_leaf_weights_in_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {'loss_function':'MAE'}\n",
    "oof_cat, prediction_cat = train_model(X=X_train_scaled, X_test=X_test_scaled, params=params, model_type='cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
